Step 1: Set Up EC2 Instances
Using the AWS Management Console or AWS CLI, launch three EC2 instances: one for the master node and two for the worker nodes. Ensure that the AWS EC2 instances meet the minimum requirements for running Kubernetes, including sufficient CPU, memory, and network connectivity.

Some general guidelines for minimum requirements of an Amazon EC2 instance to run a Kubernetes cluster : 

Master Node: (t2.medium recommended)

CPU: 2 vCPUs or more
RAM: 4 GB or more
Disk: 20 GB or more (for system and application binaries)
Network: Sufficient bandwidth for communication between nodes and with external services

Worker Nodes:

CPU: 1 vCPU or more (depending on workload)
RAM: 2 GB or more
Disk: 20 GB or more (for system and application binaries)
Network: Sufficient bandwidth for communication between nodes and with external services


#Commands to execute on both master node and woker node

#Assign hostnames (optional)
sudo hostnamectl set-hostname masternode
sudo hostnamectl set-hostname workernode1
sudo hostnamectl set-hostname workernode2


you can set hostnames in host file (optional)
sudo nano /etc/hosts
add masternodeip hostname
add workernodeip hostname

you can add below ff02::3 ips-all hosts in below screenshot


1.	sudo swapoff â€“a
This command turns off swap immediately â€” it stops the system from using swap space
It assumes that all memory management is happening with physical RAM only.

2. sudo sed -i '/swap/s/^/#/' /etc/fstab
This command comments out the swap entry in /etc/fstab, which is the file the system uses to mount disks and partitions at boot.
â€¢	Without this, swap will automatically re-enable after a reboot, even if you ran swapoff -a.
â€¢	So this line ensures that swap stays off permanently.

#Command to check if swap area is turned off
sudo swapon --show
if you see no results then swap is turned off


3: Install Docker
SSH into each Amazon EC2 instance and install Docker

You can use the following commands to install Docker :

sudo apt-get update
sudo apt install -y apt-transport-https ca-certificates curl software-properties-common
sudo apt install docker.io -y
docker â€“version
systemctl start docker
systemctl enable docker

#This command creates a configuration file for kubernetes and adds few entries
cat <<EOF | sudo tee /etc/modules-load.d/k8s.conf
overlay
netfileter
EOF

â€¢	Creates the file /etc/modules-load.d/k8s.conf
â€¢	Adds the required kernel modules for Kubernetes networking:
o	overlay: needed for container overlay filesystems
o	br_netfilter: enables iptables to see bridged traffic, which is essential for Kubernetes networking

sudo modprobe overlay
This is used to manually load the overlay kernel module into the running Linux kernel.

sudo modprobe br_netfilter
It allows the Linux kernel to apply iptables (or nftables) rules to bridged network traffic â€” like the traffic that flows between containers in Docker or Kubernetes clusters.

Creating another config file

cat <<EOF | sudo tee /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-iptables  = 1
net.bridge.bridge-nf-call-ip6tables = 1
net.ipv4.ip_forward                 = 1
EOF

What these do:
â€¢	bridge-nf-call-iptables: ensures bridged IPv4 traffic passes through iptables.
â€¢	bridge-nf-call-ip6tables: same, but for IPv6.
â€¢	ip_forward: allows the system to route packets â€” required for pod-to-pod communication across nodes

sudo sysctl --system
    This command applies all sysctl settings from configuration files located in:
â€¢	/etc/sysctl.conf
â€¢	/etc/sysctl.d/*.conf
â€¢	It basically tells the system:
â€¢	â€œHey, read all the sysctl config files and apply those settings now.â€


Add Kubernetes GPG key and repo:

sudo mkdir -p /etc/apt/keyrings
curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.28/deb/Release.key | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-archive-keyring.gpg

Add Kubernetes APT repo:
echo "deb [signed-by=/etc/apt/keyrings/kubernetes-archive-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.28/deb/ /" | sudo tee /etc/apt/sources.list.d/kubernetes.list

Update APT and install Kubernetes components:
sudo apt update
sudo apt install -y kubelet kubeadm kubectl


sudo apt-mark hold kubelet kubeadm kubectl
This command tells the system not to automatically upgrade these specific Kubernetes packages during regular updates:

kubelet: The agent that runs on every node and manages containers
kubeadm: Tool for initializing and managing a Kubernetes cluster
kubectl: Command-line tool to interact with the Kubernetes API
So, with apt-mark hold, you're freezing their versions.

Step 6: On the Master Node â€“ Initialize Kubernetes Cluster
Run on Master Node only:

ðŸ”¹ 1. Run kubeadm init on the master node
You can specify a pod network CIDR that matches Calico's default:
This is for claico network 
For funnel or other network pod network changes

sudo kubeadm init --pod-network-cidr=192.168.0.0/16

--pod-network-cidr=192.168.0.0/16 is required for Calico to work properly.

ðŸ”¹ 2. Set up kubectl config for your user
This allows your current user to run kubectl commands:
mkdir -p $HOME/.kube
sudo cp /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config

ðŸ”¹ 3. Install Calico networking
Apply the official Calico manifest:
kubectl apply -f https://docs.projectcalico.org/manifests/calico.yaml

ðŸ”¹ 4. Verify everything is running
Check node status:

kubectl get nodes
You should see the master node in Ready status (may take a minute or two).

Check the Calico pods:

kubectl get pods -n kube-system
You should see pods like calico-kube-controllers and calico-node running.


ðŸ”¹ 5. (Optional) Join worker nodes
On each worker node, use the kubeadm join ... command that was shown after the init. If you lost it, you can regenerate it on the master:

kubeadm token create --print-join-command

#Command to join worker nodes..we have to execute on worker node
kubeadm join 172.31.39.55:6443 --token q9rk73.bdd2zb8xqby7ufsv \
        --discovery-token-ca-cert-hash sha256:0780801b861dbd97c72f3a9f36fa1a58c9d804579cf4393f473ada427a8a88d6

